{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kernel_submission import *\n",
    "import scipy\n",
    "\n",
    "def load_train_data(filepath='data/train.csv'):\n",
    "    train_df = get_training_data(filepath)\n",
    "    train_df = clean_data(train_df)\n",
    "    train_df = train_df.reset_index()[hh_columns+['idhogar', 'Target']]\n",
    "    target_household_map = target_by_household(train_df)\n",
    "    train_df = train_df.drop(target_column, axis=1).groupby(household_id).agg(lambda x: scipy.stats.mode(x)[0])\n",
    "    train_df = train_df.join(target_household_map)\n",
    "    train_df = compress_column_data(train_df)\n",
    "    train_df = add_custom_features(train_df)\n",
    "    train_df['v2a1'] = train_df['v2a1'].astype(float)\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_train_split(df, valid_class_size):\n",
    "    v = get_balanced_data(df, valid_class_size)\n",
    "    t = pd.concat([df.reset_index(), v.reset_index()]).drop_duplicates(keep=False).set_index(household_id)\n",
    "    sample_min = target_table_breakdown(t)['total'].min()\n",
    "    t = get_balanced_data(t, sample_min)\n",
    "    return v, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_train_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Train Extreme Poverty Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "is_extreme = convert_to_binary_targets(train_df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Feed all data into cross validator - it will split out valid data itself\n",
    "data = get_balanced_data(is_extreme)\n",
    "\n",
    "# Custom scorer for cross validation\n",
    "scorer = make_scorer(f1_score, greater_is_better=True, average = 'macro')\n",
    "# Labels for training\n",
    "train_labels = np.array(list(data['Target'].astype(np.uint8)))\n",
    "# Extract the training data\n",
    "train_set = data.drop(columns = ['Id', 'Target'])\n",
    "\n",
    "pipeline = Pipeline([('imputer', Imputer(strategy = 'median')), \n",
    "                      ('scaler', MinMaxScaler())])\n",
    "# Fit and transform training data\n",
    "train_set = pipeline.fit_transform(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=10, n_jobs = -1)\n",
    "# 10 fold cross validation\n",
    "cv_score = cross_val_score(model, train_set, train_labels, cv = 10, scoring = scorer)\n",
    "\n",
    "print(f'10 Fold Cross Validation F1 Score = {round(cv_score.mean(), 4)} with std = {round(cv_score.std(), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "v_extreme, t_extreme = get_valid_train_split(is_extreme, 50)\n",
    "v_extreme['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Use our train-valid split to check classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "train_labels = np.array(list(t_extreme['Target'].astype(np.uint8)))\n",
    "train_set = t_extreme.drop(columns = ['Id', 'Target'])\n",
    "pipeline = Pipeline([('imputer', Imputer(strategy = 'median')), \n",
    "                      ('scaler', MinMaxScaler())])\n",
    "# Fit and transform training data\n",
    "train_set = pipeline.fit_transform(train_set)\n",
    "\n",
    "test_set = v_extreme.drop(columns = ['Id', 'Target'])\n",
    "test_set = pipeline.transform(test_set)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=10, n_jobs = -1)\n",
    "clf.fit(train_set, train_labels)\n",
    "\n",
    "preds = clf.predict(test_set)\n",
    "print(classification_report(v_extreme['Target'], preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Train Most Wealth Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "is_wealthy = convert_to_binary_targets(train_df, 4)\n",
    "# Feed all data into cross validator - it will split out valid data itself\n",
    "data = get_balanced_data(is_wealthy)\n",
    "data['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Custom scorer for cross validation\n",
    "scorer = make_scorer(f1_score, greater_is_better=True, average = 'macro')\n",
    "# Labels for training\n",
    "train_labels = np.array(list(data['Target'].astype(np.uint8)))\n",
    "# Extract the training data\n",
    "train_set = data.drop(columns = ['Id', 'Target'])\n",
    "\n",
    "pipeline = Pipeline([('imputer', Imputer(strategy = 'median')), \n",
    "                      ('scaler', MinMaxScaler())])\n",
    "# Fit and transform training data\n",
    "train_set = pipeline.fit_transform(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=10, n_jobs = -1)\n",
    "# 10 fold cross validation\n",
    "cv_score = cross_val_score(model, train_set, train_labels, cv = 10, scoring = scorer)\n",
    "\n",
    "print(f'10 Fold Cross Validation F1 Score = {round(cv_score.mean(), 4)} with std = {round(cv_score.std(), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "v_extreme, t_extreme = get_valid_train_split(is_wealthy, 50)\n",
    "v_extreme['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Use our train-valid split to check classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "train_labels = np.array(list(t_extreme['Target'].astype(np.uint8)))\n",
    "train_set = t_extreme.drop(columns = ['Id', 'Target'])\n",
    "pipeline = Pipeline([('imputer', Imputer(strategy = 'median')), \n",
    "                      ('scaler', MinMaxScaler())])\n",
    "# Fit and transform training data\n",
    "train_set = pipeline.fit_transform(train_set)\n",
    "\n",
    "test_set = v_extreme.drop(columns = ['Id', 'Target'])\n",
    "test_set = pipeline.transform(test_set)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=10, n_jobs = -1)\n",
    "clf.fit(train_set, train_labels)\n",
    "\n",
    "preds = clf.predict(test_set)\n",
    "print(classification_report(v_extreme['Target'], preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Target 3 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "is_3 = convert_to_binary_targets(train_df, 3)\n",
    "# Feed all data into cross validator - it will split out valid data itself\n",
    "data = get_balanced_data(is_3)\n",
    "data['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Custom scorer for cross validation\n",
    "scorer = make_scorer(f1_score, greater_is_better=True, average = 'macro')\n",
    "# Labels for training\n",
    "train_labels = np.array(list(data['Target'].astype(np.uint8)))\n",
    "# Extract the training data\n",
    "train_set = data.drop(columns = ['Id', 'Target'])\n",
    "\n",
    "pipeline = Pipeline([('imputer', Imputer(strategy = 'median')), \n",
    "                      ('scaler', MinMaxScaler())])\n",
    "# Fit and transform training data\n",
    "train_set = pipeline.fit_transform(train_set)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=10, n_jobs = -1)\n",
    "# 10 fold cross validation\n",
    "cv_score = cross_val_score(model, train_set, train_labels, cv = 10, scoring = scorer)\n",
    "\n",
    "print(f'10 Fold Cross Validation F1 Score = {round(cv_score.mean(), 4)} with std = {round(cv_score.std(), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "v, t = get_valid_train_split(is_3, 50)\n",
    "\n",
    "train_labels = np.array(list(t['Target'].astype(np.uint8)))\n",
    "train_set = t.drop(columns = ['Id', 'Target'])\n",
    "pipeline = Pipeline([('imputer', Imputer(strategy = 'median')), \n",
    "                      ('scaler', MinMaxScaler())])\n",
    "# Fit and transform training data\n",
    "train_set = pipeline.fit_transform(train_set)\n",
    "\n",
    "test_set = v.drop(columns = ['Id', 'Target'])\n",
    "test_set = pipeline.transform(test_set)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=10, n_jobs = -1)\n",
    "clf.fit(train_set, train_labels)\n",
    "\n",
    "preds = clf.predict(test_set)\n",
    "print(classification_report(v['Target'], preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train 2 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_2 = convert_to_binary_targets(train_df, 2)\n",
    "# Feed all data into cross validator - it will split out valid data itself\n",
    "data = get_balanced_data(is_2)\n",
    "data['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom scorer for cross validation\n",
    "scorer = make_scorer(f1_score, greater_is_better=True, average = 'macro')\n",
    "# Labels for training\n",
    "train_labels = np.array(list(data['Target'].astype(np.uint8)))\n",
    "# Extract the training data\n",
    "train_set = data.drop(columns = ['Id', 'Target'])\n",
    "\n",
    "pipeline = Pipeline([('imputer', Imputer(strategy = 'median')), \n",
    "                      ('scaler', MinMaxScaler())])\n",
    "# Fit and transform training data\n",
    "train_set = pipeline.fit_transform(train_set)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=10, n_jobs = -1)\n",
    "# 10 fold cross validation\n",
    "cv_score = cross_val_score(model, train_set, train_labels, cv = 10, scoring = scorer)\n",
    "\n",
    "print(f'10 Fold Cross Validation F1 Score = {round(cv_score.mean(), 4)} with std = {round(cv_score.std(), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, t = get_valid_train_split(is_2, 50)\n",
    "\n",
    "train_labels = np.array(list(t['Target'].astype(np.uint8)))\n",
    "train_set = t.drop(columns = ['Id', 'Target'])\n",
    "pipeline = Pipeline([('imputer', Imputer(strategy = 'median')), \n",
    "                      ('scaler', MinMaxScaler())])\n",
    "# Fit and transform training data\n",
    "train_set = pipeline.fit_transform(train_set)\n",
    "\n",
    "test_set = v.drop(columns = ['Id', 'Target'])\n",
    "test_set = pipeline.transform(test_set)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=10, n_jobs = -1)\n",
    "clf.fit(train_set, train_labels)\n",
    "\n",
    "preds = clf.predict(test_set)\n",
    "print(classification_report(v['Target'], preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All In One Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, t = get_valid_train_split(train_df, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(list(t['Target'].astype(np.uint8)))\n",
    "train_set = t.drop(columns = ['Id', 'Target'])\n",
    "pipeline = Pipeline([('imputer', Imputer(strategy = 'median')), \n",
    "                      ('scaler', MinMaxScaler())])\n",
    "# Fit and transform training data\n",
    "train_set = pipeline.fit_transform(train_set)\n",
    "\n",
    "test_set = v.drop(columns = ['Id', 'Target'])\n",
    "test_set = pipeline.transform(test_set)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=10, n_jobs = -1)\n",
    "clf.fit(train_set, train_labels)\n",
    "\n",
    "preds = clf.predict(test_set)\n",
    "print(classification_report(v['Target'], preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make 4 Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, t = get_valid_train_split(train_df, 50)\n",
    "# Get all from train_df except v data, split into binary for each class, get balanced data\n",
    "t = pd.concat([train_df.reset_index(), v.reset_index()]).drop_duplicates(keep=False).set_index(household_id)\n",
    "t['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_1 = get_balanced_data(convert_to_binary_targets(t, 1))\n",
    "is_2 = get_balanced_data(convert_to_binary_targets(t, 2))\n",
    "is_3 = get_balanced_data(convert_to_binary_targets(t, 3))\n",
    "is_4 = get_balanced_data(convert_to_binary_targets(t, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_4['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_clf(df):\n",
    "    train_labels = np.array(list(df['Target'].astype(np.uint8)))\n",
    "    train_set = df.drop(columns = ['Id', 'Target'])\n",
    "    pipeline = Pipeline([('imputer', Imputer(strategy = 'median')), \n",
    "                          ('scaler', MinMaxScaler())])\n",
    "    train_set = pipeline.fit_transform(train_set)\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=10, n_jobs = -1)\n",
    "    clf.fit(train_set, train_labels)\n",
    "    return pipeline, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_clf(pipeline, clf, test_data):\n",
    "    test_set = test_data.drop(columns = ['Id', 'Target'])\n",
    "    test_set = pipeline.transform(test_set)\n",
    "    return clf.predict_proba(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_1, c_1 = train_clf(is_1)\n",
    "pred_1 = pd.DataFrame(test_clf(p_1, c_1, convert_to_binary_targets(v, 1))).set_index(v['Id']).rename(columns={0:'0',1:'1'})\n",
    "\n",
    "p_2, c_2 = train_clf(is_2)\n",
    "pred_2 = pd.DataFrame(test_clf(p_2, c_2, convert_to_binary_targets(v, 2))).set_index(v['Id']).rename(columns={0:'0',1:'2'})\n",
    "\n",
    "p_3, c_3 = train_clf(is_3)\n",
    "pred_3 = pd.DataFrame(test_clf(p_3, c_3, convert_to_binary_targets(v, 3))).set_index(v['Id']).rename(columns={0:'0',1:'3'})\n",
    "\n",
    "p_4, c_4 = train_clf(is_4)\n",
    "pred_4 = pd.DataFrame(test_clf(p_4, c_4, convert_to_binary_targets(v, 4))).set_index(v['Id']).rename(columns={0:'0',1:'4'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([pred_1['1'], pred_2['2'], pred_3['3'], pred_4['4']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boost_results(df):\n",
    "    df['1'] = df['1']*1.25\n",
    "    df['2'] = df['2']*1.15\n",
    "    df['3'] = df['3']*1.05\n",
    "    df['4'] = df['4']*0.95\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = boost_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = results.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = v.reset_index().drop(columns=['idhogar']).set_index('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = pd.concat([preds, v2['Target']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = j.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(j['Target'], j[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(j['Target'], j[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix = confusion_matrix(j['Target'], j[0], labels=[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set a few plotting defaults\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['patch.edgecolor'] = 'k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=['1','2','3','4']\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
