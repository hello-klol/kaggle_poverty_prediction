{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minnie/.pyenv/versions/3.6.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/minnie/.pyenv/versions/3.6.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from kernel_submission import *\n",
    "train_df = get_training_data('data/train.csv')\n",
    "train_df = clean_data(train_df)\n",
    "train_df = train_df.reset_index()[hh_columns+['idhogar', 'Target']]\n",
    "target_household_map = target_by_household(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minnie/.ve/poverty-prediction/lib/python3.6/site-packages/scipy/stats/stats.py:245: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "train_df = train_df.drop(target_column, axis=1).groupby(household_id).agg(lambda x: scipy.stats.mode(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minnie/.ve/poverty-prediction/lib/python3.6/site-packages/pandas/core/computation/expressions.py:180: UserWarning: evaluating in Python space because the '+' operator is not supported by numexpr for the bool dtype, use '|' instead\n",
      "  .format(op=op_str, alt_op=unsupported[op_str]))\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.join(target_household_map)\n",
    "train_df = compress_column_data(train_df)\n",
    "train_df = add_custom_features(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "is_extreme = convert_to_binary_targets(train_df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2766\n",
       "1     222\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_extreme['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "# f1_score(y_true, y_predicted, average = 'macro`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set a few plotting defaults\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['patch.edgecolor'] = 'k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = is_extreme\n",
    "train['v2a1'] = train['v2a1'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from collections import OrderedDict\n",
    "# from numpy.linalg import LinAlgError\n",
    "\n",
    "# plt.figure(figsize = (20, 4))\n",
    "# plt.style.use('fivethirtyeight')\n",
    "\n",
    "# # Color mapping\n",
    "# colors = OrderedDict({0: 'blue', 1: 'green'})\n",
    "# poverty_mapping = OrderedDict({1: 'extreme', 0: 'not extreme'})\n",
    "\n",
    "# # Iterate through the float columns\n",
    "# for i, col in enumerate(train.select_dtypes('float')):\n",
    "#     try:\n",
    "#         ax = plt.subplot(2, 2, i + 1)\n",
    "#         # Iterate through the poverty levels\n",
    "#         for poverty_level, color in colors.items():\n",
    "#             # Plot each poverty level as a separate line\n",
    "#             sns.kdeplot(train.loc[train['Target'] == poverty_level, col].dropna(), \n",
    "#                         ax = ax, color = color, label = poverty_mapping[poverty_level])\n",
    "\n",
    "#         plt.title(f'{col.capitalize()} Distribution'); plt.xlabel(f'{col}'); plt.ylabel('Density')\n",
    "#     except LinAlgError:\n",
    "#         pass\n",
    "\n",
    "# plt.subplots_adjust(top = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train.select_dtypes(np.int64).nunique().value_counts().sort_index().plot.bar(color = 'blue', \n",
    "#                                                                              figsize = (6, 4),\n",
    "#                                                                             edgecolor = 'k', linewidth = 1)\n",
    "# plt.xlabel('Number of Unique Values'); plt.ylabel('Count')\n",
    "# plt.title('Count of Unique Values in Integer Columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Find way of scaling household material against wealth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_categoricals(x, y, data, annotate = True):\n",
    "    \"\"\"Plot counts of two categoricals.\n",
    "    Size is raw count for each grouping.\n",
    "    Percentages are for a given value of y.\"\"\"\n",
    "    \n",
    "    # Raw counts \n",
    "    raw_counts = pd.DataFrame(data.groupby(y)[x].value_counts(normalize = False))\n",
    "    raw_counts = raw_counts.rename(columns = {x: 'raw_count'})\n",
    "    \n",
    "    # Calculate counts for each group of x and y\n",
    "    counts = pd.DataFrame(data.groupby(y)[x].value_counts(normalize = True))\n",
    "    \n",
    "    # Rename the column and reset the index\n",
    "    counts = counts.rename(columns = {x: 'normalized_count'}).reset_index()\n",
    "    counts['percent'] = 100 * counts['normalized_count']\n",
    "    \n",
    "    # Add the raw count\n",
    "    counts['raw_count'] = list(raw_counts['raw_count'])\n",
    "    \n",
    "    plt.figure(figsize = (14, 10))\n",
    "    # Scatter plot sized by percent\n",
    "    plt.scatter(counts[x], counts[y], edgecolor = 'k', color = 'lightgreen',\n",
    "                s = 100 * np.sqrt(counts['raw_count']), marker = 'o',\n",
    "                alpha = 0.6, linewidth = 1.5)\n",
    "    \n",
    "    if annotate:\n",
    "        # Annotate the plot with text\n",
    "        for i, row in counts.iterrows():\n",
    "            # Put text with appropriate offsets\n",
    "            plt.annotate(xy = (row[x] - (1 / counts[x].nunique()), \n",
    "                               row[y] - (0.15 / counts[y].nunique())),\n",
    "                         color = 'navy',\n",
    "                         s = f\"{round(row['percent'], 1)}%\")\n",
    "        \n",
    "    # Set tick marks\n",
    "    plt.yticks(counts[y].unique())\n",
    "    plt.xticks(counts[x].unique())\n",
    "    \n",
    "    # Transform min and max to evenly space in square root domain\n",
    "    sqr_min = int(np.sqrt(raw_counts['raw_count'].min()))\n",
    "    sqr_max = int(np.sqrt(raw_counts['raw_count'].max()))\n",
    "    \n",
    "    # 5 sizes for legend\n",
    "    msizes = list(range(sqr_min, sqr_max,\n",
    "                        int(( sqr_max - sqr_min) / 5)))\n",
    "    markers = []\n",
    "    \n",
    "    # Markers for legend\n",
    "    for size in msizes:\n",
    "        markers.append(plt.scatter([], [], s = 100 * size, \n",
    "                                   label = f'{int(round(np.square(size) / 100) * 100)}', \n",
    "                                   color = 'lightgreen',\n",
    "                                   alpha = 0.6, edgecolor = 'k', linewidth = 1.5))\n",
    "        \n",
    "    # Legend and formatting\n",
    "    plt.legend(handles = markers, title = 'Counts',\n",
    "               labelspacing = 3, handletextpad = 2,\n",
    "               fontsize = 16,\n",
    "               loc = (1.10, 0.19))\n",
    "    \n",
    "    plt.annotate(f'* Size represents raw count while % is for a given y value.',\n",
    "                 xy = (0, 1), xycoords = 'figure points', size = 10)\n",
    "    \n",
    "    # Adjust axes limits\n",
    "    plt.xlim((counts[x].min() - (6 / counts[x].nunique()), \n",
    "              counts[x].max() + (6 / counts[x].nunique())))\n",
    "    plt.ylim((counts[y].min() - (4 / counts[y].nunique()), \n",
    "              counts[y].max() + (4 / counts[y].nunique())))\n",
    "    plt.grid(None)\n",
    "    plt.xlabel(f\"{x}\"); plt.ylabel(f\"{y}\"); plt.title(f\"{y} vs {x}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['elimbasu3' 'elimbasu2' 'elimbasu5' 'elimbasu1' 'elimbasu4' 'elimbasu6'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1c4b47d07976>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# material = ['elimbasu3',  'elimbasu2', 'elimbasu5', 'elimbasu1', 'elimbasu4', 'elimbasu6']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmaterial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'elimbasu3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'elimbasu2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'elimbasu5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'elimbasu1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'elimbasu4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'elimbasu6'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmaterial\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.ve/poverty-prediction/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2682\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2683\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.ve/poverty-prediction/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2724\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2725\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2726\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2727\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.ve/poverty-prediction/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[0;32m-> 1327\u001b[0;31m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['elimbasu3' 'elimbasu2' 'elimbasu5' 'elimbasu1' 'elimbasu4' 'elimbasu6'] not in index\""
     ]
    }
   ],
   "source": [
    "# material = ['elimbasu3',  'elimbasu2', 'elimbasu5', 'elimbasu1', 'elimbasu4', 'elimbasu6']\n",
    "material = ['elimbasu3', 'elimbasu2', 'elimbasu5', 'elimbasu1', 'elimbasu4', 'elimbasu6']\n",
    "features = train[material]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "features = compress_columns(features, 'material', material).join(train['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "features = get_balanced_data(features, 222, 6)\n",
    "plot_categoricals('Target','material', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "desc = {'elimbasu1':'=1 if rubbish disposal mainly by tanker truck',\n",
    "    'elimbasu2':'=1 if rubbish disposal mainly by botan hollow or buried',\n",
    "    'elimbasu3':'=1 if rubbish disposal mainly by burning',\n",
    "    'elimbasu4':'=1 if rubbish disposal mainly by throwing in an unoccupied space',\n",
    "    'elimbasu5':'\"=1 if rubbish disposal mainly by throwing in river,  creek or sea\"',\n",
    "    'elimbasu6':'=1 if rubbish disposal mainly other'}\n",
    "desc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for m in material:\n",
    "    print(desc.get(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# df = compress_columns(df, 'wall-material', ['paredfibras', 'pareddes', 'paredzinc', 'paredzocalo', 'paredmad', 'paredpreb', 'paredblolad', 'paredother'])\n",
    "# df = compress_columns(df, 'floor-material', ['pisonotiene', 'pisonatur', 'pisomadera', 'pisocemento', 'pisomoscer', 'pisoother'])\n",
    "# df = compress_columns(df, 'roof-material', ['techocane', 'techoentrepiso', 'techozinc', 'techootro'])\n",
    "# df = compress_columns(df, 'water-provision', ['abastaguano', 'abastaguafuera','abastaguadentro'])\n",
    "# df = compress_columns(df, 'house-ownership', ['tipovivi4', 'tipovivi5', 'tipovivi1', 'tipovivi3', 'tipovivi2'])\n",
    "# df = compress_columns(df, 'toilet-system', ['sanitario5', 'sanitario6', 'sanitario1', 'sanitario3', 'sanitario2'])\n",
    "# df = compress_columns(df, 'cooking-energy', ['energcocinar4', 'energcocinar1', 'energcocinar3', 'energcocinar2'])\n",
    "# df = compress_columns(df, 'rubbish-disposal', ['elimbasu3', 'elimbasu2', 'elimbasu5', 'elimbasu1', 'elimbasu4', 'elimbasu6'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_extreme['v2a1'] = is_extreme['v2a1'].astype(float)\n",
    "is_extreme['warning'] = is_extreme['warning'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = get_balanced_data(is_extreme, 50)\n",
    "train_df = pd.concat([is_extreme.reset_index(), valid_df.reset_index()]).drop_duplicates(keep=False).set_index(household_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = valid_df.drop(columns=['cielorazo','r4m1','hogar_nin'])\n",
    "train_df = train_df.drop(columns=['cielorazo','r4m1','hogar_nin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2716\n",
       "1     172\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_balanced_data(train_df, 172)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most negatively correlated variables:\n",
      "edjefe           -0.319729\n",
      "wrf              -0.308317\n",
      "meaneduc         -0.301676\n",
      "wall-quality     -0.297905\n",
      "cooking-energy   -0.276121\n",
      "Name: Target, dtype: float64\n",
      "\n",
      "Most positively correlated variables:\n",
      "r4h1            0.222420\n",
      "warning         0.287465\n",
      "r4t1            0.298408\n",
      "overcrowding    0.321672\n",
      "Target          1.000000\n",
      "Name: Target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Most negatively correlated variables:')\n",
    "print(train_df.corr()['Target'].sort_values().head())\n",
    "\n",
    "print('\\nMost positively correlated variables:')\n",
    "print(train_df.corr()['Target'].sort_values().dropna().tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minnie/.ve/poverty-prediction/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Custom scorer for cross validation\n",
    "scorer = make_scorer(f1_score, greater_is_better=True, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels for training\n",
    "train_labels = np.array(list(train_df['Target'].astype(np.uint8)))\n",
    "\n",
    "# Extract the training data\n",
    "train_set = train_df.drop(columns = ['Id', 'Target'])\n",
    "test_set = valid_df.drop(columns = ['Id', 'Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(train_set.columns)\n",
    "\n",
    "pipeline = Pipeline([('imputer', Imputer(strategy = 'median')), \n",
    "                      ('scaler', MinMaxScaler())])\n",
    "\n",
    "# Fit and transform training data\n",
    "train_set = pipeline.fit_transform(train_set)\n",
    "test_set = pipeline.transform(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Fold Cross Validation F1 Score = 0.7464 with std = 0.0966\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=10, n_jobs = -1)\n",
    "# 10 fold cross validation\n",
    "cv_score = cross_val_score(model, train_set, train_labels, cv = 10, scoring = scorer)\n",
    "\n",
    "print(f'10 Fold Cross Validation F1 Score = {round(cv_score.mean(), 4)} with std = {round(cv_score.std(), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.64      0.69        50\n",
      "          1       0.68      0.78      0.73        50\n",
      "\n",
      "avg / total       0.71      0.71      0.71       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=10, n_jobs = -1)\n",
    "clf.fit(train_set, train_labels)\n",
    "preds = clf.predict(test_set)\n",
    "print(classification_report(valid_df['Target'], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_probabilities = clf.predict_proba(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36, 0.64],\n",
       "       [0.28, 0.72],\n",
       "       [0.81, 0.19],\n",
       "       [0.28, 0.72],\n",
       "       [0.45, 0.55],\n",
       "       [0.86, 0.14],\n",
       "       [0.42, 0.58],\n",
       "       [0.24, 0.76],\n",
       "       [0.77, 0.23],\n",
       "       [0.86, 0.14],\n",
       "       [0.67, 0.33],\n",
       "       [0.83, 0.17],\n",
       "       [0.34, 0.66],\n",
       "       [0.92, 0.08],\n",
       "       [0.88, 0.12],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.48, 0.52],\n",
       "       [0.95, 0.05],\n",
       "       [0.37, 0.63],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.55, 0.45],\n",
       "       [0.55, 0.45],\n",
       "       [0.55, 0.45],\n",
       "       [0.89, 0.11],\n",
       "       [0.65, 0.35],\n",
       "       [0.44, 0.56],\n",
       "       [0.32, 0.68],\n",
       "       [0.27, 0.73],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.88, 0.12],\n",
       "       [0.32, 0.68],\n",
       "       [0.97, 0.03],\n",
       "       [0.66, 0.34],\n",
       "       [0.66, 0.34],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.29, 0.71],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.05, 0.95],\n",
       "       [0.71, 0.29],\n",
       "       [0.43, 0.57],\n",
       "       [0.24, 0.76],\n",
       "       [0.85, 0.15],\n",
       "       [0.53, 0.47],\n",
       "       [0.68, 0.32],\n",
       "       [0.45, 0.55],\n",
       "       [0.26, 0.74],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.94, 0.06],\n",
       "       [0.15, 0.85],\n",
       "       [0.93, 0.07],\n",
       "       [0.75, 0.25],\n",
       "       [0.56, 0.44],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.66, 0.34],\n",
       "       [0.47, 0.53],\n",
       "       [0.32, 0.68],\n",
       "       [0.29, 0.71],\n",
       "       [0.83, 0.17],\n",
       "       [0.11, 0.89],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.17, 0.83],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.33, 0.67],\n",
       "       [0.72, 0.28],\n",
       "       [0.27, 0.73],\n",
       "       [0.66, 0.34],\n",
       "       [0.07, 0.93],\n",
       "       [0.27, 0.73],\n",
       "       [0.41, 0.59],\n",
       "       [0.17, 0.83],\n",
       "       [0.53, 0.47],\n",
       "       [0.19, 0.81],\n",
       "       [0.55, 0.45],\n",
       "       [0.52, 0.48],\n",
       "       [0.18, 0.82],\n",
       "       [0.28, 0.72],\n",
       "       [0.87, 0.13],\n",
       "       [0.44, 0.56],\n",
       "       [0.33, 0.67],\n",
       "       [0.09, 0.91],\n",
       "       [0.14, 0.86],\n",
       "       [0.1 , 0.9 ],\n",
       "       [0.19, 0.81],\n",
       "       [0.47, 0.53],\n",
       "       [0.42, 0.58],\n",
       "       [0.33, 0.67],\n",
       "       [0.09, 0.91],\n",
       "       [0.28, 0.72],\n",
       "       [0.37, 0.63],\n",
       "       [0.2 , 0.8 ],\n",
       "       [0.16, 0.84],\n",
       "       [0.19, 0.81],\n",
       "       [0.35, 0.65],\n",
       "       [0.35, 0.65],\n",
       "       [0.23, 0.77],\n",
       "       [0.58, 0.42],\n",
       "       [0.26, 0.74],\n",
       "       [0.47, 0.53],\n",
       "       [0.69, 0.31],\n",
       "       [0.31, 0.69]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
